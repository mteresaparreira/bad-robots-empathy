{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77a9d8f",
   "metadata": {},
   "source": [
    "### Conversion of GridSearch log data to a df\n",
    "\n",
    "The below code converts the logs generated whilst performing GridSearch for complex model architecture & converts the important information from the logs to a value in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5100751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb85d99a",
   "metadata": {},
   "source": [
    "Merge all the ```results_LSTM.txt``` files from all the scripts to a single .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bf9de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text files combined successfully!\n"
     ]
    }
   ],
   "source": [
    "files_to_ignore = ['.DS_Store']\n",
    "\n",
    "# Specify the LSTM script whose logs are to be considered\n",
    "logs_path = '../../model_results/bilstm_results/script_3/'\n",
    "\n",
    "# Obtain all the consequent log folders\n",
    "log_folders = os.listdir(logs_path)\n",
    "log_folders = [folder for folder in log_folders if folder not in files_to_ignore]\n",
    "# print(log_folders)\n",
    "\n",
    "# Specify the final merged results.txt file path\n",
    "final_results_file_path = logs_path + 'final_merged_results'\n",
    "\n",
    "if not os.path.exists(final_results_file_path):\n",
    "    os.makedirs(final_results_file_path)\n",
    "\n",
    "final_results_txt_file_path = final_results_file_path + '/final_results.txt'\n",
    "\n",
    "# Merge all the results to a single results.txt file\n",
    "def merge_results(source_path, destination_path):\n",
    "    try:\n",
    "        with open(destination_path, 'a', encoding='utf-8') as destination_file:\n",
    "            with open(source_path, 'r', encoding='utf-8') as source_file:\n",
    "                    content = source_file.read()\n",
    "                    destination_file.write(content)\n",
    "            destination_file.write('\\n')  # Optionally add a newline between file contents\n",
    "    except Exception as e:\n",
    "        print(f'Exception {e} thrown for {source_path}')\n",
    "    print(\"Text files combined successfully!\")\n",
    "\n",
    "# Iterate over all the log folders in the model script folder and obtain the path of the results_LSTM.txt paths\n",
    "for folder in sorted(log_folders):\n",
    "    folder_path = logs_path + folder\n",
    "    source_result_path = folder_path + '/results_BiLSTM.txt'\n",
    "#     print(f'Folder: {folder}, Results Text File: {source_result_path}')\n",
    "    merge_results(source_result_path, final_results_txt_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0a3e00",
   "metadata": {},
   "source": [
    "The below code identifies the beginning and the end of a search combination in the log file and creates the content within that to be considered as a single search instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd804d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(final_results_txt_file_path, 'r') as results_file:\n",
    "    results_content = results_file.read()\n",
    "\n",
    "cleaned_content = [line for line in results_content.split('\\n')]\n",
    "\n",
    "search_combinations = []\n",
    "current_instance = []\n",
    "\n",
    "for line in cleaned_content:\n",
    "    if re.search(r'BEGIN SEARCH : for Script', line):\n",
    "        if current_instance:\n",
    "            search_combinations.append(current_instance)\n",
    "        current_instance = [line]\n",
    "    elif re.search(r'END SEARCH', line):\n",
    "        if current_instance:\n",
    "            current_instance.append(line)\n",
    "            search_combinations.append(current_instance)\n",
    "        current_instance = []\n",
    "    elif current_instance:\n",
    "        current_instance.append(line)\n",
    "\n",
    "# # Print the search_combinations\n",
    "# for idx, instance in enumerate(search_combinations, start=1):\n",
    "#     print(f\"Instance {idx}:\")\n",
    "#     for line in instance:\n",
    "#         print(line)\n",
    "#     print(\"\\n\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841135d",
   "metadata": {},
   "source": [
    "The below code iterates through all search combination instances and extracts the relevant information needed and stores it in the form of a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d579f4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_info = []\n",
    "\n",
    "for search in search_combinations:\n",
    "    script_num = 0\n",
    "    search_count = 0\n",
    "    sequence_length = 0\n",
    "    unit = 0\n",
    "    dropout_rate = 0\n",
    "    activation_function = ''\n",
    "    loss_function = ''\n",
    "    optimizer = ''\n",
    "    num_epochs = 0\n",
    "    batch_size = 0\n",
    "    seed_value = 0\n",
    "    \n",
    "    training_loss = 0\n",
    "    training_accuracy = 0\n",
    "    validation_loss = 0\n",
    "    validation_accuracy = 0\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    \n",
    "    model_parameters = ''\n",
    "    model_keys = ''\n",
    "    \n",
    "    classification_report = ''\n",
    "    capture_classification = False  # Flag to capture classification report content\n",
    "    confusion_matrix = ''\n",
    "\n",
    "    for line in search:\n",
    "        script_match = re.search(r'Script (\\d+)', line)\n",
    "        if script_match:\n",
    "            script_num = ast.literal_eval(script_match.group(1))\n",
    "        search_match = re.search(r'BEGIN SEARCH : (\\d+)', line)\n",
    "        if search_match:\n",
    "            search_count = ast.literal_eval(search_match.group(1))\n",
    "        sequence_length_match = re.search(r'Sequence Length = (\\d+)', line)\n",
    "        if sequence_length_match:\n",
    "            sequence_length = ast.literal_eval(sequence_length_match.group(1))\n",
    "        units_match = re.search(r'Units = (\\d+)', line)\n",
    "        if units_match:\n",
    "            units = ast.literal_eval(units_match.group(1))\n",
    "        dropout_match = re.search(r'Dropout = (\\d+\\.?\\d*)', line)\n",
    "        if dropout_match:\n",
    "            dropout_rate = ast.literal_eval((dropout_match.group(1)))\n",
    "        activation_match = re.search(r'Activation = (.+)', line)\n",
    "        if activation_match:\n",
    "            activation_function = activation_match.group(1)\n",
    "        loss_match = re.search(r'Loss Function = (.+)', line)\n",
    "        if loss_match:\n",
    "            loss_function = loss_match.group(1)\n",
    "        optimizer_match = re.search(r'Optimizer = (.+)', line)\n",
    "        if optimizer_match:\n",
    "            optimizer = optimizer_match.group(1)\n",
    "        epochs_match = re.search(r'Epochs = (\\d+)', line)\n",
    "        if epochs_match:\n",
    "            num_epochs = ast.literal_eval(epochs_match.group(1))\n",
    "        batch_size_match = re.search(r'Batch Size = (\\d+)', line)\n",
    "        if batch_size_match:\n",
    "            batch_size = ast.literal_eval(batch_size_match.group(1))\n",
    "        seed_match = re.search(r'Seed Value = (\\d+)', line)\n",
    "        if seed_match:\n",
    "            seed_value = ast.literal_eval(seed_match.group(1))\n",
    "\n",
    "        training_loss_match = re.search(r'Training Loss:\\s+(\\d+\\.\\d+)', line)\n",
    "        if training_loss_match:\n",
    "            training_loss = ast.literal_eval(training_loss_match.group(1))\n",
    "        training_accuracy_match = re.search(r'Training Accuracy:\\s+(\\d+\\.\\d+)', line)\n",
    "        if training_accuracy_match:\n",
    "            training_accuracy = ast.literal_eval(training_accuracy_match.group(1))\n",
    "        validation_loss_match = re.search(r'Validation Loss:\\s+(\\d+\\.\\d+)', line)\n",
    "        if validation_loss_match:\n",
    "            validation_loss = ast.literal_eval(validation_loss_match.group(1))\n",
    "        validation_accuracy_match = re.search(r'Validation Accuracy:\\s+(\\d+\\.\\d+)', line)\n",
    "        if validation_accuracy_match:\n",
    "            validation_accuracy = ast.literal_eval(validation_accuracy_match.group(1))\n",
    "        test_loss_match = re.search(r'Test Loss:\\s+(\\d+\\.\\d+)', line)\n",
    "        if test_loss_match:\n",
    "            test_loss = ast.literal_eval(test_loss_match.group(1))\n",
    "        test_accuracy_match = re.search(r'Test Accuracy:\\s+(\\d+\\.\\d+)', line)\n",
    "        if test_accuracy_match:\n",
    "            test_accuracy = ast.literal_eval(test_accuracy_match.group(1))\n",
    "\n",
    "        model_params_match = re.search(r\"Model Parameters: (.+)\", line)\n",
    "        if model_params_match:\n",
    "            model_parameters = ast.literal_eval(model_params_match.group(1))\n",
    "        model_keys_match = re.search(r\"Model Keys: (.+)\", line)\n",
    "        if model_keys_match:\n",
    "            model_keys = model_keys_match.group(1)\n",
    "\n",
    "        class_report_start = re.search(r'------------ CLASSIFICATION REPORT ------------', line)\n",
    "        if class_report_start:\n",
    "            capture_classification = True  # Start capturing content\n",
    "            continue  # Skip this line as it's just a marker\n",
    "        elif capture_classification and re.search(r'------------ CONFUSION MATRIX ------------', line):\n",
    "            capture_classification = False  # Stop capturing on \"Confusion Matrix\" marker\n",
    "        elif capture_classification:\n",
    "            if line.strip() != '':\n",
    "                classification_report += line + '\\n'\n",
    "\n",
    "        # Capture the lines within the \"CONFUSION MATRIX\" section\n",
    "        if re.search(r'Confusion matrix saved for', line):\n",
    "            confusion_matrix = line.split('Confusion matrix saved for ')[-1]  # Extract file name\n",
    "            break  # Stop capturing after saving the confusion matrix filename\n",
    "        \n",
    "        \n",
    "    capture_classification_row = False\n",
    "    precision_values = {}\n",
    "    recall_values = {}\n",
    "    f1_scores = {}\n",
    "    macro_avgs = {}\n",
    "    weighted_avgs = {}\n",
    "\n",
    "    # RE pattern for obtaining classification reports values\n",
    "    class_values_pattern = r'^\\s*(\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+'\n",
    "    macro_avg_pattern = r'\\s*macro avg\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)'\n",
    "    weighted_avg_pattern = r'\\s*weighted avg\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)'\n",
    "\n",
    "    # Once we have the classification report, let us extract all the other information in it\n",
    "    for row in classification_report.split('\\n'):\n",
    "        row_headers_start_match = re.search(\"precision    recall  f1-score   support\", row)\n",
    "        if row_headers_start_match:\n",
    "            capture_classification_row = True\n",
    "            continue\n",
    "        elif capture_classification_row and re.search('macro avg', row):\n",
    "            macro_avg_match = re.search(macro_avg_pattern, row)\n",
    "            if macro_avg_match:\n",
    "                macro_avgs['precision'] = ast.literal_eval(macro_avg_match.group(1))\n",
    "                macro_avgs['recall'] = ast.literal_eval(macro_avg_match.group(2))\n",
    "                macro_avgs['f1_score'] = ast.literal_eval(macro_avg_match.group(3))\n",
    "                \n",
    "        elif capture_classification_row and re.search('weighted avg', row):\n",
    "            weighted_avg_match = re.search(weighted_avg_pattern, row)\n",
    "            if weighted_avg_match:\n",
    "                weighted_avgs['precision'] = ast.literal_eval(weighted_avg_match.group(1))\n",
    "                weighted_avgs['recall'] = ast.literal_eval(weighted_avg_match.group(2))\n",
    "                weighted_avgs['f1_score'] = ast.literal_eval(weighted_avg_match.group(3))\n",
    "                capture_classification_row = False\n",
    "#                 break\n",
    "        elif capture_classification_row and re.search(r'\\d+', row):\n",
    "            class_values_match = re.search(class_values_pattern, row)\n",
    "            if class_values_match:\n",
    "                class_label = ast.literal_eval(class_values_match.group(1))\n",
    "                precision_value = ast.literal_eval(class_values_match.group(2))\n",
    "                recall_value = ast.literal_eval(class_values_match.group(3))\n",
    "                f1_score = ast.literal_eval(class_values_match.group(4))\n",
    "                \n",
    "                precision_values[class_label] = precision_value\n",
    "                recall_values[class_label] = recall_value\n",
    "                f1_scores[class_label] = f1_score\n",
    "                \n",
    "        \n",
    "\n",
    "#     print(f'Script Number: {script_num}, Search Number: {search_count}')\n",
    "#     print(f'Sequence Length: {sequence_length}')\n",
    "#     print(f'Units: {units}')\n",
    "#     print(f'Dropout Rate: {dropout_rate}')\n",
    "#     print(f'Activation Function: {activation_function}')\n",
    "#     print(f'Loss Function: {loss_function}')\n",
    "#     print(f'Optimizer: {optimizer}')\n",
    "#     print(f'Number of Epochs: {num_epochs}')\n",
    "#     print(f'Batch Size: {batch_size}')\n",
    "#     print(f'Seed Value: {seed_value}')\n",
    "\n",
    "#     print(f'Training Loss: {training_loss}')\n",
    "#     print(f'Training Accuracy: {training_accuracy}')\n",
    "#     print(f'Validation Loss: {validation_loss}')\n",
    "#     print(f'Validation Accuracy: {validation_accuracy}')\n",
    "#     print(f'Test Loss: {test_loss}')\n",
    "#     print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "#     print(f'Model Parameters: {model_parameters}')\n",
    "#     print(f'Model Keys: {model_keys}')\n",
    "\n",
    "#     print(f'Classification Report:\\n{classification_report}')\n",
    "#     print(f'Confusion Matrix: {confusion_matrix}')\n",
    "#     print(f'Precison Values : {precision_values}')\n",
    "#     print(f'Recall Values: {recall_values}')\n",
    "#     print(f'F1-Scores: {f1_scores}')\n",
    "#     print(f'Macro Averages: {macro_avgs}')\n",
    "#     print(f'Weighted Averages: {weighted_avgs}')\n",
    "\n",
    "    # Append all the collected information to the search_info list if needed\n",
    "    search_info.append({\n",
    "        'script_num': script_num,\n",
    "        'search_count': search_count,\n",
    "        'sequence_length': sequence_length,\n",
    "        'units': units,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'activation_function': activation_function,\n",
    "        'loss_function': loss_function,\n",
    "        'optimizer': optimizer,\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'seed_value': seed_value,\n",
    "        'training_loss': training_loss,\n",
    "        'training_accuracy': training_accuracy,\n",
    "        'validation_loss': validation_loss,\n",
    "        'validation_accuracy': validation_accuracy,\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'precision_values': precision_values,\n",
    "        'recall_values': recall_values,\n",
    "        'f1_scores': f1_scores,\n",
    "        'macro_averages': macro_avgs,\n",
    "        'weighted_averages': weighted_avgs,\n",
    "        'model_parameters': model_parameters,\n",
    "        'model_keys': model_keys,\n",
    "        'confusion_matrix': confusion_matrix,\n",
    "        'classification_report': classification_report,\n",
    "        'precision_values': precision_values,\n",
    "        'recall_values': recall_values,\n",
    "        'f1_scores': f1_scores,\n",
    "        'macro_averages': macro_avgs,\n",
    "        'weighted_averages': weighted_avgs,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2971a998",
   "metadata": {},
   "source": [
    "The below code converts the search_combinations_information dictionary to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "150bee5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_num</th>\n",
       "      <th>search_count</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>precision_values</th>\n",
       "      <th>recall_values</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>macro_averages</th>\n",
       "      <th>weighted_averages</th>\n",
       "      <th>model_parameters</th>\n",
       "      <th>model_keys</th>\n",
       "      <th>classification_report</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>250</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3947</td>\n",
       "      <td>{0: 0.65, 1: 0.3, 2: 0.23}</td>\n",
       "      <td>{0: 0.34, 1: 0.6, 2: 0.25}</td>\n",
       "      <td>{0: 0.45, 1: 0.4, 2: 0.24}</td>\n",
       "      <td>{'precision': 0.39, 'recall': 0.4, 'f1_score':...</td>\n",
       "      <td>{'precision': 0.49, 'recall': 0.39, 'f1_score'...</td>\n",
       "      <td>{'verbose': '2', 'epochs': 250, 'steps': 59}</td>\n",
       "      <td>dict_keys(['loss', 'accuracy', 'val_loss', 'va...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>confusion_matrix_15_32_0_sigmoid_categorical_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>250</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>{0: 0.64, 1: 0.3, 2: 0.22}</td>\n",
       "      <td>{0: 0.38, 1: 0.62, 2: 0.16}</td>\n",
       "      <td>{0: 0.48, 1: 0.41, 2: 0.18}</td>\n",
       "      <td>{'precision': 0.39, 'recall': 0.39, 'f1_score'...</td>\n",
       "      <td>{'precision': 0.48, 'recall': 0.41, 'f1_score'...</td>\n",
       "      <td>{'verbose': '2', 'epochs': 250, 'steps': 30}</td>\n",
       "      <td>dict_keys(['loss', 'accuracy', 'val_loss', 'va...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>confusion_matrix_15_32_0_sigmoid_categorical_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>250</td>\n",
       "      <td>2048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4222</td>\n",
       "      <td>{0: 0.61, 1: 0.31, 2: 0.2}</td>\n",
       "      <td>{0: 0.43, 1: 0.6, 2: 0.1}</td>\n",
       "      <td>{0: 0.51, 1: 0.4, 2: 0.13}</td>\n",
       "      <td>{'precision': 0.37, 'recall': 0.38, 'f1_score'...</td>\n",
       "      <td>{'precision': 0.46, 'recall': 0.42, 'f1_score'...</td>\n",
       "      <td>{'verbose': '2', 'epochs': 250, 'steps': 15}</td>\n",
       "      <td>dict_keys(['loss', 'accuracy', 'val_loss', 'va...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>confusion_matrix_15_32_0_sigmoid_categorical_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>250</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>{0: 0.6, 1: 0.29, 2: 0.3}</td>\n",
       "      <td>{0: 0.62, 1: 0.4, 2: 0.07}</td>\n",
       "      <td>{0: 0.61, 1: 0.34, 2: 0.12}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.37, 'f1_score':...</td>\n",
       "      <td>{'precision': 0.47, 'recall': 0.47, 'f1_score'...</td>\n",
       "      <td>{'verbose': '2', 'epochs': 250, 'steps': 8}</td>\n",
       "      <td>dict_keys(['loss', 'accuracy', 'val_loss', 'va...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>confusion_matrix_15_32_0_sigmoid_categorical_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>{0: 0.64, 1: 0.28, 2: 0.21}</td>\n",
       "      <td>{0: 0.3, 1: 0.58, 2: 0.23}</td>\n",
       "      <td>{0: 0.41, 1: 0.38, 2: 0.22}</td>\n",
       "      <td>{'precision': 0.38, 'recall': 0.37, 'f1_score'...</td>\n",
       "      <td>{'precision': 0.47, 'recall': 0.37, 'f1_score'...</td>\n",
       "      <td>{'verbose': '2', 'epochs': 500, 'steps': 59}</td>\n",
       "      <td>dict_keys(['loss', 'accuracy', 'val_loss', 'va...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>confusion_matrix_15_32_0_sigmoid_categorical_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>3</td>\n",
       "      <td>1019</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>250</td>\n",
       "      <td>2048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3617</td>\n",
       "      <td>{0: 0.61, 1: 0.27, 2: 0.29}</td>\n",
       "      <td>{0: 0.28, 1: 0.58, 2: 0.28}</td>\n",
       "      <td>{0: 0.39, 1: 0.37, 2: 0.28}</td>\n",
       "      <td>{'precision': 0.39, 'recall': 0.38, 'f1_score'...</td>\n",
       "      <td>{'precision': 0.46, 'recall': 0.36, 'f1_score'...</td>\n",
       "      <td>{'verbose': '2', 'epochs': 250, 'steps': 15}</td>\n",
       "      <td>dict_keys(['loss', 'accuracy', 'val_loss', 'va...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>confusion_matrix_15_64_0.6_sigmoid_categorical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>3</td>\n",
       "      <td>1020</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>250</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3522</td>\n",
       "      <td>{0: 0.65, 1: 0.27, 2: 0.19}</td>\n",
       "      <td>{0: 0.28, 1: 0.61, 2: 0.18}</td>\n",
       "      <td>{0: 0.39, 1: 0.38, 2: 0.18}</td>\n",
       "      <td>{'precision': 0.37, 'recall': 0.36, 'f1_score'...</td>\n",
       "      <td>{'precision': 0.47, 'recall': 0.35, 'f1_score'...</td>\n",
       "      <td>{'verbose': '2', 'epochs': 250, 'steps': 8}</td>\n",
       "      <td>dict_keys(['loss', 'accuracy', 'val_loss', 'va...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>confusion_matrix_15_64_0.6_sigmoid_categorical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>3</td>\n",
       "      <td>1021</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>{0: 0.53, 1: 0.26, 2: 0.18}</td>\n",
       "      <td>{0: 0.11, 1: 0.69, 2: 0.18}</td>\n",
       "      <td>{0: 0.18, 1: 0.37, 2: 0.18}</td>\n",
       "      <td>{'precision': 0.32, 'recall': 0.33, 'f1_score'...</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.28, 'f1_score':...</td>\n",
       "      <td>{'verbose': '2', 'epochs': 500, 'steps': 59}</td>\n",
       "      <td>dict_keys(['loss', 'accuracy', 'val_loss', 'va...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>confusion_matrix_15_64_0.6_sigmoid_categorical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>3</td>\n",
       "      <td>1022</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>500</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>{0: 0.6, 1: 0.32, 2: 0.0}</td>\n",
       "      <td>{0: 0.69, 1: 0.42, 2: 0.0}</td>\n",
       "      <td>{0: 0.64, 1: 0.36, 2: 0.0}</td>\n",
       "      <td>{'precision': 0.31, 'recall': 0.37, 'f1_score'...</td>\n",
       "      <td>{'precision': 0.43, 'recall': 0.51, 'f1_score'...</td>\n",
       "      <td>{'verbose': '2', 'epochs': 500, 'steps': 30}</td>\n",
       "      <td>dict_keys(['loss', 'accuracy', 'val_loss', 'va...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>confusion_matrix_15_64_0.6_sigmoid_categorical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>3</td>\n",
       "      <td>1023</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>500</td>\n",
       "      <td>2048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4238</td>\n",
       "      <td>{0: 0.59, 1: 0.28, 2: 0.0}</td>\n",
       "      <td>{0: 0.47, 1: 0.58, 2: 0.0}</td>\n",
       "      <td>{0: 0.52, 1: 0.38, 2: 0.0}</td>\n",
       "      <td>{'precision': 0.29, 'recall': 0.35, 'f1_score'...</td>\n",
       "      <td>{'precision': 0.41, 'recall': 0.42, 'f1_score'...</td>\n",
       "      <td>{'verbose': '2', 'epochs': 500, 'steps': 15}</td>\n",
       "      <td>dict_keys(['loss', 'accuracy', 'val_loss', 'va...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>confusion_matrix_15_64_0.6_sigmoid_categorical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      script_num  search_count  sequence_length  units  dropout_rate  \\\n",
       "0              3             1               15     32           0.0   \n",
       "1              3             2               15     32           0.0   \n",
       "2              3             3               15     32           0.0   \n",
       "3              3             4               15     32           0.0   \n",
       "4              3             5               15     32           0.0   \n",
       "...          ...           ...              ...    ...           ...   \n",
       "1018           3          1019               15     64           0.6   \n",
       "1019           3          1020               15     64           0.6   \n",
       "1020           3          1021               15     64           0.6   \n",
       "1021           3          1022               15     64           0.6   \n",
       "1022           3          1023               15     64           0.6   \n",
       "\n",
       "     activation_function             loss_function optimizer  num_epochs  \\\n",
       "0                sigmoid  categorical_crossentropy       SGD         250   \n",
       "1                sigmoid  categorical_crossentropy       SGD         250   \n",
       "2                sigmoid  categorical_crossentropy       SGD         250   \n",
       "3                sigmoid  categorical_crossentropy       SGD         250   \n",
       "4                sigmoid  categorical_crossentropy       SGD         500   \n",
       "...                  ...                       ...       ...         ...   \n",
       "1018             sigmoid  categorical_crossentropy      Adam         250   \n",
       "1019             sigmoid  categorical_crossentropy      Adam         250   \n",
       "1020             sigmoid  categorical_crossentropy      Adam         500   \n",
       "1021             sigmoid  categorical_crossentropy      Adam         500   \n",
       "1022             sigmoid  categorical_crossentropy      Adam         500   \n",
       "\n",
       "      batch_size  ...  test_accuracy             precision_values  \\\n",
       "0            512  ...         0.3947   {0: 0.65, 1: 0.3, 2: 0.23}   \n",
       "1           1024  ...         0.4087   {0: 0.64, 1: 0.3, 2: 0.22}   \n",
       "2           2048  ...         0.4222   {0: 0.61, 1: 0.31, 2: 0.2}   \n",
       "3           4096  ...         0.4737    {0: 0.6, 1: 0.29, 2: 0.3}   \n",
       "4            512  ...         0.3660  {0: 0.64, 1: 0.28, 2: 0.21}   \n",
       "...          ...  ...            ...                          ...   \n",
       "1018        2048  ...         0.3617  {0: 0.61, 1: 0.27, 2: 0.29}   \n",
       "1019        4096  ...         0.3522  {0: 0.65, 1: 0.27, 2: 0.19}   \n",
       "1020         512  ...         0.2759  {0: 0.53, 1: 0.26, 2: 0.18}   \n",
       "1021        1024  ...         0.5058    {0: 0.6, 1: 0.32, 2: 0.0}   \n",
       "1022        2048  ...         0.4238   {0: 0.59, 1: 0.28, 2: 0.0}   \n",
       "\n",
       "                    recall_values                    f1_scores  \\\n",
       "0      {0: 0.34, 1: 0.6, 2: 0.25}   {0: 0.45, 1: 0.4, 2: 0.24}   \n",
       "1     {0: 0.38, 1: 0.62, 2: 0.16}  {0: 0.48, 1: 0.41, 2: 0.18}   \n",
       "2       {0: 0.43, 1: 0.6, 2: 0.1}   {0: 0.51, 1: 0.4, 2: 0.13}   \n",
       "3      {0: 0.62, 1: 0.4, 2: 0.07}  {0: 0.61, 1: 0.34, 2: 0.12}   \n",
       "4      {0: 0.3, 1: 0.58, 2: 0.23}  {0: 0.41, 1: 0.38, 2: 0.22}   \n",
       "...                           ...                          ...   \n",
       "1018  {0: 0.28, 1: 0.58, 2: 0.28}  {0: 0.39, 1: 0.37, 2: 0.28}   \n",
       "1019  {0: 0.28, 1: 0.61, 2: 0.18}  {0: 0.39, 1: 0.38, 2: 0.18}   \n",
       "1020  {0: 0.11, 1: 0.69, 2: 0.18}  {0: 0.18, 1: 0.37, 2: 0.18}   \n",
       "1021   {0: 0.69, 1: 0.42, 2: 0.0}   {0: 0.64, 1: 0.36, 2: 0.0}   \n",
       "1022   {0: 0.47, 1: 0.58, 2: 0.0}   {0: 0.52, 1: 0.38, 2: 0.0}   \n",
       "\n",
       "                                         macro_averages  \\\n",
       "0     {'precision': 0.39, 'recall': 0.4, 'f1_score':...   \n",
       "1     {'precision': 0.39, 'recall': 0.39, 'f1_score'...   \n",
       "2     {'precision': 0.37, 'recall': 0.38, 'f1_score'...   \n",
       "3     {'precision': 0.4, 'recall': 0.37, 'f1_score':...   \n",
       "4     {'precision': 0.38, 'recall': 0.37, 'f1_score'...   \n",
       "...                                                 ...   \n",
       "1018  {'precision': 0.39, 'recall': 0.38, 'f1_score'...   \n",
       "1019  {'precision': 0.37, 'recall': 0.36, 'f1_score'...   \n",
       "1020  {'precision': 0.32, 'recall': 0.33, 'f1_score'...   \n",
       "1021  {'precision': 0.31, 'recall': 0.37, 'f1_score'...   \n",
       "1022  {'precision': 0.29, 'recall': 0.35, 'f1_score'...   \n",
       "\n",
       "                                      weighted_averages  \\\n",
       "0     {'precision': 0.49, 'recall': 0.39, 'f1_score'...   \n",
       "1     {'precision': 0.48, 'recall': 0.41, 'f1_score'...   \n",
       "2     {'precision': 0.46, 'recall': 0.42, 'f1_score'...   \n",
       "3     {'precision': 0.47, 'recall': 0.47, 'f1_score'...   \n",
       "4     {'precision': 0.47, 'recall': 0.37, 'f1_score'...   \n",
       "...                                                 ...   \n",
       "1018  {'precision': 0.46, 'recall': 0.36, 'f1_score'...   \n",
       "1019  {'precision': 0.47, 'recall': 0.35, 'f1_score'...   \n",
       "1020  {'precision': 0.4, 'recall': 0.28, 'f1_score':...   \n",
       "1021  {'precision': 0.43, 'recall': 0.51, 'f1_score'...   \n",
       "1022  {'precision': 0.41, 'recall': 0.42, 'f1_score'...   \n",
       "\n",
       "                                  model_parameters  \\\n",
       "0     {'verbose': '2', 'epochs': 250, 'steps': 59}   \n",
       "1     {'verbose': '2', 'epochs': 250, 'steps': 30}   \n",
       "2     {'verbose': '2', 'epochs': 250, 'steps': 15}   \n",
       "3      {'verbose': '2', 'epochs': 250, 'steps': 8}   \n",
       "4     {'verbose': '2', 'epochs': 500, 'steps': 59}   \n",
       "...                                            ...   \n",
       "1018  {'verbose': '2', 'epochs': 250, 'steps': 15}   \n",
       "1019   {'verbose': '2', 'epochs': 250, 'steps': 8}   \n",
       "1020  {'verbose': '2', 'epochs': 500, 'steps': 59}   \n",
       "1021  {'verbose': '2', 'epochs': 500, 'steps': 30}   \n",
       "1022  {'verbose': '2', 'epochs': 500, 'steps': 15}   \n",
       "\n",
       "                                             model_keys  \\\n",
       "0     dict_keys(['loss', 'accuracy', 'val_loss', 'va...   \n",
       "1     dict_keys(['loss', 'accuracy', 'val_loss', 'va...   \n",
       "2     dict_keys(['loss', 'accuracy', 'val_loss', 'va...   \n",
       "3     dict_keys(['loss', 'accuracy', 'val_loss', 'va...   \n",
       "4     dict_keys(['loss', 'accuracy', 'val_loss', 'va...   \n",
       "...                                                 ...   \n",
       "1018  dict_keys(['loss', 'accuracy', 'val_loss', 'va...   \n",
       "1019  dict_keys(['loss', 'accuracy', 'val_loss', 'va...   \n",
       "1020  dict_keys(['loss', 'accuracy', 'val_loss', 'va...   \n",
       "1021  dict_keys(['loss', 'accuracy', 'val_loss', 'va...   \n",
       "1022  dict_keys(['loss', 'accuracy', 'val_loss', 'va...   \n",
       "\n",
       "                                  classification_report  \\\n",
       "0                   precision    recall  f1-score   ...   \n",
       "1                   precision    recall  f1-score   ...   \n",
       "2                   precision    recall  f1-score   ...   \n",
       "3                   precision    recall  f1-score   ...   \n",
       "4                   precision    recall  f1-score   ...   \n",
       "...                                                 ...   \n",
       "1018                precision    recall  f1-score   ...   \n",
       "1019                precision    recall  f1-score   ...   \n",
       "1020                precision    recall  f1-score   ...   \n",
       "1021                precision    recall  f1-score   ...   \n",
       "1022                precision    recall  f1-score   ...   \n",
       "\n",
       "                                       confusion_matrix  \n",
       "0     confusion_matrix_15_32_0_sigmoid_categorical_c...  \n",
       "1     confusion_matrix_15_32_0_sigmoid_categorical_c...  \n",
       "2     confusion_matrix_15_32_0_sigmoid_categorical_c...  \n",
       "3     confusion_matrix_15_32_0_sigmoid_categorical_c...  \n",
       "4     confusion_matrix_15_32_0_sigmoid_categorical_c...  \n",
       "...                                                 ...  \n",
       "1018  confusion_matrix_15_64_0.6_sigmoid_categorical...  \n",
       "1019  confusion_matrix_15_64_0.6_sigmoid_categorical...  \n",
       "1020  confusion_matrix_15_64_0.6_sigmoid_categorical...  \n",
       "1021  confusion_matrix_15_64_0.6_sigmoid_categorical...  \n",
       "1022  confusion_matrix_15_64_0.6_sigmoid_categorical...  \n",
       "\n",
       "[1023 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = [\n",
    "    'script_num',\n",
    "    'search_count',\n",
    "    'sequence_length',\n",
    "    'units',\n",
    "    'dropout_rate',\n",
    "    'activation_function',\n",
    "    'loss_function',\n",
    "    'optimizer',\n",
    "    'num_epochs',\n",
    "    'batch_size',\n",
    "    'seed_value',\n",
    "    'training_loss',\n",
    "    'training_accuracy',\n",
    "    'validation_loss',\n",
    "    'validation_accuracy',\n",
    "    'test_loss',\n",
    "    'test_accuracy',\n",
    "    'precision_values',\n",
    "    'recall_values',\n",
    "    'f1_scores',\n",
    "    'macro_averages',\n",
    "    'weighted_averages',\n",
    "    'model_parameters',\n",
    "    'model_keys',\n",
    "    'classification_report',\n",
    "    'confusion_matrix'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(search_info, columns = df_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b37ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df_path = final_results_file_path +  '/bilstm_script_3_gridSearch_results.csv'\n",
    "df_no_duplicates = df.drop_duplicates(subset=['search_count'])\n",
    "df_no_duplicates.to_csv(f'{final_results_df_path}', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1534733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
